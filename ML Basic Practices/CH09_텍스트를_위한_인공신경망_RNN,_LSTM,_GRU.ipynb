{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CH09 텍스트를 위한 인공신경망 : RNN, LSTM, GRU.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ex1jgqry5wrt"
      },
      "source": [
        "<h1> Machine Learning Seminar </h1>\n",
        "\n",
        "- CH 09 텍스트를 위한 인공 신경망\n",
        "- 2021.10.12\n",
        "\n",
        "<br><hr><br>\n",
        "\n",
        "<h2> 순차 데이터 (Sequential Data) </h2>\n",
        "\n",
        "- 순차 데이터: 순서가 의미가 있으며, 순서가 달라질 경우 의미가 손상되는 데이터\n",
        "- 시간적 의미가 있는 경우 Temporal Sequence / 일정한 시간차라면 Time Series (시계열)\n",
        "- ex) DNA 염기서열, 세계 기온변화, 샘플링된 소리 신호, 주식 데이터\n",
        "\n",
        "<br>\n",
        "\n",
        "<h2> Resampling </h2>\n",
        "\n",
        ": Temporal Sequence를 Time Series로 변환하기 위한 리샘플링(Resampling) 과정\n",
        "- 취득된 데이터(Temporal Sequence)를 이용해 신호 보간 (Interpolation)하고, 균일 시간 간격으로 이를 샘플링 하는 과정\n",
        "\n",
        "<br>\n",
        "\n",
        "<h2> RNN (Recurrent Neural Network) </h2>\n",
        "\n",
        "- 타임 스텝으로 펼쳐진 순환 신경망\n",
        "- 셀: 순환층, 활성화 함수(tanh - hyperbolic tangent function)에 의한 값이 순환적으로 입력됨\n",
        "- 각 타임 스텝마다 동일한 가중치를 사용(가중치 공유)\n",
        "- 출력 결과 값(은닉 상태:Hidden State)\n",
        "\n",
        "<br>\n",
        "\n",
        "- 셀의 가중치 : 순환층에 입력되는 특성의 개수 * 순환층의 뉴런 개수\n",
        "- 시퀀스: 하나의 샘플\n",
        "\n",
        "- 토큰 : 하나의 단어를 정수로 매핑 (1개의 토큰 -> 1 타임스텝)\n",
        "\n",
        "<br><br><hr><br>\n",
        "\n",
        "\n",
        "<h2> 순환 신경망으로 IMDB 리뷰 분류하기 <h2>\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcYcqsp4_vjd",
        "outputId": "b0a7ad96-780f-44ec-b75c-4ccf4aa30f3f"
      },
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "\n",
        "(train_input, train_target), (test_input, test_target) = imdb.load_data(\n",
        "    num_words=500) # num_words = 어휘 사전을 500개 사용하도록\n",
        "\n",
        "print(train_input.shape, test_input.shape) # train_input [리뷰 1, 리뷰2, 리뷰3...] (25000,) (25000,)\n",
        "\n",
        "\n",
        "print(len(train_input[0])) # 218: 첫번째 리뷰의 토큰: 218개\n",
        "\n",
        "\n",
        "print(len(train_input[1])) # 189: 두번째 리뷰의 토큰: 189개\n",
        "\n",
        "\n",
        "print(train_input[0]) # 첫번째 리뷰의 토큰(정수)들 모두 출력\n",
        "\n",
        "# 타깃 데이터 출력\n",
        "print(train_target[:20]) # 0:부정, 1:긍정"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(25000,) (25000,)\n",
            "218\n",
            "189\n",
            "[1, 14, 22, 16, 43, 2, 2, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 2, 112, 50, 2, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 2, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 2, 38, 76, 15, 13, 2, 4, 22, 17, 2, 17, 12, 16, 2, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 2, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 2, 36, 71, 43, 2, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n",
            "[1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "Sm2PUTNYA64r",
        "outputId": "1bb7f8e4-a314-4f94-c1bc-c3edfd26dc48"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 훈련, 테스트 데이터 분리 (훈련: 20,000개, 테스트: 5,000개)\n",
        "train_input, val_input, train_target, val_target = train_test_split(\n",
        "    train_input, train_target, test_size=0.2, random_state=42)\n",
        "\n",
        "import numpy as np\n",
        "lengths = np.array([len(x) for x in train_input]) # 모든 리뷰의 길이\n",
        "print(np.mean(lengths), np.median(lengths)) # 리뷰 길이의 평균값(239개의 토큰값), 중간값(178) => 매우 긴 리뷰들이 소수 있음을 확인할 수 있음\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(lengths)\n",
        "plt.xlabel('length')\n",
        "plt.ylabel('frequency')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "239.00925 178.0\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mtevPq5Bprb"
      },
      "source": [
        "<br>\n",
        "\n",
        "<h3> 패딩 작업 </h3>\n",
        "- 비어있는 토큰 자리를 모두 0으로 채워 넣는 작업, 또는 지정한 길이보다 긴 시퀀스를 자르는 과정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDGUQWrTB_RM",
        "outputId": "67763c64-c94f-4071-e9f7-9632ccfdfcba"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# 입력 데이터의 길이를 100개의 토큰 길이로 잡는다. (maxlen = 100), 100보다 작으면 sequence padding과정이 이루어짐 -> 타임 스텝의 개수: 100\n",
        "train_seq = pad_sequences(train_input, maxlen=100) # maxlen 보다 긴 시퀀스의 앞부분을 자름 (뒷 부분의 정보가 더 유용하리라 기대하기 때문)\n",
        "\n",
        "print(train_seq.shape) # (20000, 100) -> 20,000개의 리뷰 데이터, 100개의 타임 스탭(토큰 개수)\n",
        "\n",
        "\n",
        "print(train_seq[0])\n",
        "\n",
        "print(train_input[0][-10:]) # 앞부분이 0으로 채워져있음을 확인 가능\n",
        "\n",
        "\n",
        "print(train_seq[5])\n",
        "\n",
        "\n",
        "val_seq = pad_sequences(val_input, maxlen=100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(20000, 100)\n",
            "[ 10   4  20   9   2 364 352   5  45   6   2   2  33 269   8   2 142   2\n",
            "   5   2  17  73  17 204   5   2  19  55   2   2  92  66 104  14  20  93\n",
            "  76   2 151  33   4  58  12 188   2 151  12 215  69 224 142  73 237   6\n",
            "   2   7   2   2 188   2 103  14  31  10  10 451   7   2   5   2  80  91\n",
            "   2  30   2  34  14  20 151  50  26 131  49   2  84  46  50  37  80  79\n",
            "   6   2  46   7  14  20  10  10 470 158]\n",
            "[6, 2, 46, 7, 14, 20, 10, 10, 470, 158]\n",
            "[  0   0   0   0   1   2 195  19  49   2   2 190   4   2 352   2 183  10\n",
            "  10  13  82  79   4   2  36  71 269   8   2  25  19  49   7   4   2   2\n",
            "   2   2   2  10  10  48  25  40   2  11   2   2  40   2   2   5   4   2\n",
            "   2  95  14 238  56 129   2  10  10  21   2  94 364 352   2   2  11 190\n",
            "  24 484   2   7  94 205 405  10  10  87   2  34  49   2   7   2   2   2\n",
            "   2   2 290   2  46  48  64  18   4   2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UhlNlofD5B7"
      },
      "source": [
        "<br>\n",
        "\n",
        "<h3> 순환 신경망 모델 만들기 </h3\n",
        "\n",
        "- SimpleRNN 클래스"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiMTsAjmC3vj",
        "outputId": "cffaedc0-5f27-45b7-fb1a-eea3e3d54333"
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "model = keras.Sequential()\n",
        "\n",
        "model.add(keras.layers.SimpleRNN(8, input_shape=(100, 500))) # 100개의 타임 스텝, 어휘 사전의 500개의 단어(토큰)을 사용하도록 설정\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "# 원-핫 인코딩 (500개의 원소 중 1개를 제외하고 나머지는 0값으로 설정)\n",
        "train_oh = keras.utils.to_categorical(train_seq) \n",
        "print(train_oh.shape) # (20000, 100, 500) -> 20,000개의 데이터 , 100개의 타임 스텝, 500개의 어휘 사전\n",
        "\n",
        "\n",
        "print(train_oh[0][0][:12])\n",
        "\n",
        "\n",
        "print(np.sum(train_oh[0][0]))\n",
        "\n",
        "\n",
        "val_oh = keras.utils.to_categorical(val_seq)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 4072 개 (500개 어휘사전 * 뉴런 8개 + 64개의 가중치(은닉상태크기*뉴런 개수) + 절편8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(20000, 100, 500)\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "1.0\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_1 (SimpleRNN)     (None, 8)                 4072      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 4,081\n",
            "Trainable params: 4,081\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxtrziPZFBdC"
      },
      "source": [
        "<br>\n",
        "\n",
        "<h3> 순환 신경망 훈련 </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQ3abU9tE_vb",
        "outputId": "29c345c5-2a31-4954-e66e-6eb75ab56c44"
      },
      "source": [
        "rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)\n",
        "model.compile(optimizer=rmsprop, loss='binary_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint('best-simplernn-model.h5', \n",
        "                                                save_best_only=True)\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3,\n",
        "                                                  restore_best_weights=True)\n",
        "\n",
        "\n",
        "# RMSprop 객체 별도로 생성하여 학습률을 0.0001로 지정\n",
        "# 에포크 횟수 100, 배치 크기 64\n",
        "history = model.fit(train_oh, train_target, epochs=100, batch_size=64,\n",
        "                    validation_data=(val_oh, val_target),\n",
        "                    callbacks=[checkpoint_cb, early_stopping_cb])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "313/313 [==============================] - 15s 45ms/step - loss: 0.6956 - accuracy: 0.5076 - val_loss: 0.6930 - val_accuracy: 0.5166\n",
            "Epoch 2/100\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.6883 - accuracy: 0.5429 - val_loss: 0.6824 - val_accuracy: 0.5722\n",
            "Epoch 3/100\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.6752 - accuracy: 0.5907 - val_loss: 0.6702 - val_accuracy: 0.6026\n",
            "Epoch 4/100\n",
            "313/313 [==============================] - 14s 44ms/step - loss: 0.6580 - accuracy: 0.6347 - val_loss: 0.6504 - val_accuracy: 0.6526\n",
            "Epoch 5/100\n",
            "313/313 [==============================] - 14s 44ms/step - loss: 0.6380 - accuracy: 0.6724 - val_loss: 0.6326 - val_accuracy: 0.6774\n",
            "Epoch 6/100\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.6189 - accuracy: 0.6962 - val_loss: 0.6150 - val_accuracy: 0.7016\n",
            "Epoch 7/100\n",
            "313/313 [==============================] - 14s 44ms/step - loss: 0.6003 - accuracy: 0.7164 - val_loss: 0.5977 - val_accuracy: 0.7088\n",
            "Epoch 8/100\n",
            "313/313 [==============================] - 14s 44ms/step - loss: 0.5824 - accuracy: 0.7320 - val_loss: 0.5814 - val_accuracy: 0.7280\n",
            "Epoch 9/100\n",
            "313/313 [==============================] - 14s 44ms/step - loss: 0.5655 - accuracy: 0.7430 - val_loss: 0.5729 - val_accuracy: 0.7296\n",
            "Epoch 10/100\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.5510 - accuracy: 0.7531 - val_loss: 0.5552 - val_accuracy: 0.7396\n",
            "Epoch 11/100\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.5364 - accuracy: 0.7631 - val_loss: 0.5439 - val_accuracy: 0.7446\n",
            "Epoch 12/100\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.5245 - accuracy: 0.7699 - val_loss: 0.5310 - val_accuracy: 0.7578\n",
            "Epoch 13/100\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.5131 - accuracy: 0.7760 - val_loss: 0.5231 - val_accuracy: 0.7632\n",
            "Epoch 14/100\n",
            "313/313 [==============================] - 14s 44ms/step - loss: 0.5027 - accuracy: 0.7804 - val_loss: 0.5151 - val_accuracy: 0.7642\n",
            "Epoch 15/100\n",
            "313/313 [==============================] - 15s 47ms/step - loss: 0.4939 - accuracy: 0.7852 - val_loss: 0.5056 - val_accuracy: 0.7730\n",
            "Epoch 16/100\n",
            "313/313 [==============================] - 14s 43ms/step - loss: 0.4855 - accuracy: 0.7874 - val_loss: 0.4980 - val_accuracy: 0.7762\n",
            "Epoch 17/100\n",
            "313/313 [==============================] - 14s 44ms/step - loss: 0.4780 - accuracy: 0.7895 - val_loss: 0.4932 - val_accuracy: 0.7808\n",
            "Epoch 18/100\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.4708 - accuracy: 0.7940 - val_loss: 0.4869 - val_accuracy: 0.7796\n",
            "Epoch 19/100\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.4645 - accuracy: 0.7977 - val_loss: 0.4830 - val_accuracy: 0.7818\n",
            "Epoch 20/100\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.4591 - accuracy: 0.8007 - val_loss: 0.4883 - val_accuracy: 0.7728\n",
            "Epoch 21/100\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.4539 - accuracy: 0.8033 - val_loss: 0.4800 - val_accuracy: 0.7832\n",
            "Epoch 22/100\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.4491 - accuracy: 0.8034 - val_loss: 0.4716 - val_accuracy: 0.7816\n",
            "Epoch 23/100\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.4449 - accuracy: 0.8070 - val_loss: 0.4752 - val_accuracy: 0.7836\n",
            "Epoch 24/100\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.4408 - accuracy: 0.8087 - val_loss: 0.4701 - val_accuracy: 0.7838\n",
            "Epoch 25/100\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.4372 - accuracy: 0.8101 - val_loss: 0.4659 - val_accuracy: 0.7848\n",
            "Epoch 26/100\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.4337 - accuracy: 0.8098 - val_loss: 0.4664 - val_accuracy: 0.7842\n",
            "Epoch 27/100\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.4310 - accuracy: 0.8119 - val_loss: 0.4628 - val_accuracy: 0.7858\n",
            "Epoch 28/100\n",
            "313/313 [==============================] - 14s 46ms/step - loss: 0.4284 - accuracy: 0.8135 - val_loss: 0.4592 - val_accuracy: 0.7870\n",
            "Epoch 29/100\n",
            "313/313 [==============================] - 14s 44ms/step - loss: 0.4250 - accuracy: 0.8149 - val_loss: 0.4623 - val_accuracy: 0.7858\n",
            "Epoch 30/100\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.4228 - accuracy: 0.8153 - val_loss: 0.4588 - val_accuracy: 0.7858\n",
            "Epoch 31/100\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.4204 - accuracy: 0.8151 - val_loss: 0.4551 - val_accuracy: 0.7880\n",
            "Epoch 32/100\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.4188 - accuracy: 0.8170 - val_loss: 0.4578 - val_accuracy: 0.7904\n",
            "Epoch 33/100\n",
            "313/313 [==============================] - 14s 46ms/step - loss: 0.4163 - accuracy: 0.8172 - val_loss: 0.4585 - val_accuracy: 0.7884\n",
            "Epoch 34/100\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.4143 - accuracy: 0.8180 - val_loss: 0.4561 - val_accuracy: 0.7894\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e482g06HFg4S"
      },
      "source": [
        "<br><br>\n",
        "\n",
        "원-핫 인코딩으로는 앞뒤 단어들과의 관계를 살펴보기 어려움\n",
        "<br><br>\n",
        "\n",
        "\n",
        "<h2> 단어 임베딩 (Word Embedding) </h2>\n",
        "\n",
        "- 단어들끼리의 연관성 추가\n",
        "- 각 단어를 고정된 크기의 실수 벡터로 바꾸어줌\n",
        "- Embedding 클래스 추가\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XW5tZ8hgGD_z",
        "outputId": "8c507d9f-5c55-40d8-e268-2edb10116e4b"
      },
      "source": [
        "model2 = keras.Sequential()\n",
        "\n",
        "model2.add(keras.layers.Embedding(500, 16, input_length=100))\n",
        "model2.add(keras.layers.SimpleRNN(8))\n",
        "model2.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model2.summary()\n",
        "\n",
        "rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)\n",
        "model2.compile(optimizer=rmsprop, loss='binary_crossentropy', \n",
        "               metrics=['accuracy'])\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint('best-embedding-model.h5', \n",
        "                                                save_best_only=True)\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3,\n",
        "                                                  restore_best_weights=True)\n",
        "\n",
        "history = model2.fit(train_seq, train_target, epochs=100, batch_size=64,\n",
        "                     validation_data=(val_seq, val_target),\n",
        "                     callbacks=[checkpoint_cb, early_stopping_cb])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 100, 16)           8000      \n",
            "_________________________________________________________________\n",
            "simple_rnn_2 (SimpleRNN)     (None, 8)                 200       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 8,209\n",
            "Trainable params: 8,209\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VsOPrSJGfsT"
      },
      "source": [
        "<br>\n",
        "\n",
        "RNN의 한계점\n",
        "- 기본 순환층은 긴 시퀀스를 학습하기 어려움 -> 시퀀스가 길수록 은닉 상태에 담긴 정보가 점차 희석되며, 멀리 떨어져 있는 단어 정보를 인식하는데 어려움이 있음\n",
        "\n",
        "<br><br>\n",
        "\n",
        "<h2> LSTM (Long Short-Term Memory </h2>\n",
        "\n",
        "- RNN의 한계점을 보완하여, 단기 기억을 오래 기억하기 위해 고안된 모델\n",
        "- 순환되는 상태가 2 개 (은닉 상태 + 셀 상태)\n",
        "\n",
        "<br>\n",
        "\n",
        "<h3> Cell State </h3>\n",
        "\n",
        "- 다음 층으로 전달되지 않고 LSTM 셀에서 순환만 되는 값\n",
        "- 셀 상태의 계산 과정 -> 입력과 은닉 상태를 또다른 가중치에 곱한 후 시그모이드 함수를 통화시키고, 이전 타임스텝의 셀상태와 곱하여 새로운 셀 상태 생성 -> tanh 함수를 통과하여 새로운 은닉 상태 생성\n",
        "<br>\n",
        "\n",
        "- Forget gate layer : 셀 상태에 있는 정보를 제거하는 역할의 삭제 게이트\n",
        "- Input gate layer : 새로운 정보를 셀 상태에 추가하는 역할의 입력 게이트\n",
        "- Output gate layer : 셀 상태가 다음 은닉 상태로 출력하는 역할의 출력 게이트\n",
        "\n",
        "<br><br>\n",
        "\n",
        "<h3> LSTM 신경망 훈련 </h3>\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwQpfpSwIshI",
        "outputId": "911298e7-23c7-4497-9b2e-0a4a25243b4f"
      },
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "(train_input, train_target), (test_input, test_target) = imdb.load_data(\n",
        "    num_words=500)\n",
        "\n",
        "train_input, val_input, train_target, val_target = train_test_split(\n",
        "    train_input, train_target, test_size=0.2, random_state=42)\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "train_seq = pad_sequences(train_input, maxlen=100)\n",
        "val_seq = pad_sequences(val_input, maxlen=100)\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "model = keras.Sequential()\n",
        "\n",
        "model.add(keras.layers.Embedding(500, 16, input_length=100))\n",
        "\n",
        "model.add(keras.layers.LSTM(8)) # Embedding 이후, SimpleRNN 이 아닌 LSTM 클래스 사용\n",
        "# 작은 셀 4개 -> 200에서 4배 늘어 800개의 파라미터 값을 갖게 됨\n",
        "\n",
        "\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 100, 16)           8000      \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 8)                 800       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 8,809\n",
            "Trainable params: 8,809\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yx0MysiK0ha"
      },
      "source": [
        "<h3> LSTM 모델 훈련 </h3>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4t5zOK_KZQL",
        "outputId": "6ff3ea5d-8934-40a3-872e-d1217b0b4ae6"
      },
      "source": [
        "rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)\n",
        "model.compile(optimizer=rmsprop, loss='binary_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint('best-lstm-model.h5', \n",
        "                                                save_best_only=True)\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3,\n",
        "                                                  restore_best_weights=True)\n",
        "\n",
        "history = model.fit(train_seq, train_target, epochs=100, batch_size=64,\n",
        "                    validation_data=(val_seq, val_target),\n",
        "                    callbacks=[checkpoint_cb, early_stopping_cb])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "313/313 [==============================] - 14s 37ms/step - loss: 0.6920 - accuracy: 0.5553 - val_loss: 0.6908 - val_accuracy: 0.5986\n",
            "Epoch 2/100\n",
            "313/313 [==============================] - 11s 35ms/step - loss: 0.6871 - accuracy: 0.6452 - val_loss: 0.6817 - val_accuracy: 0.6616\n",
            "Epoch 3/100\n",
            "313/313 [==============================] - 11s 35ms/step - loss: 0.6513 - accuracy: 0.6945 - val_loss: 0.6193 - val_accuracy: 0.6884\n",
            "Epoch 4/100\n",
            "313/313 [==============================] - 11s 35ms/step - loss: 0.6007 - accuracy: 0.7057 - val_loss: 0.5919 - val_accuracy: 0.7106\n",
            "Epoch 5/100\n",
            "313/313 [==============================] - 11s 35ms/step - loss: 0.5740 - accuracy: 0.7311 - val_loss: 0.5671 - val_accuracy: 0.7388\n",
            "Epoch 6/100\n",
            "313/313 [==============================] - 11s 35ms/step - loss: 0.5527 - accuracy: 0.7494 - val_loss: 0.5494 - val_accuracy: 0.7434\n",
            "Epoch 7/100\n",
            "313/313 [==============================] - 11s 35ms/step - loss: 0.5331 - accuracy: 0.7620 - val_loss: 0.5321 - val_accuracy: 0.7540\n",
            "Epoch 8/100\n",
            "313/313 [==============================] - 11s 35ms/step - loss: 0.5146 - accuracy: 0.7729 - val_loss: 0.5145 - val_accuracy: 0.7676\n",
            "Epoch 9/100\n",
            "313/313 [==============================] - 11s 35ms/step - loss: 0.4973 - accuracy: 0.7825 - val_loss: 0.5005 - val_accuracy: 0.7688\n",
            "Epoch 10/100\n",
            "313/313 [==============================] - 11s 35ms/step - loss: 0.4812 - accuracy: 0.7892 - val_loss: 0.4849 - val_accuracy: 0.7808\n",
            "Epoch 11/100\n",
            "313/313 [==============================] - 11s 35ms/step - loss: 0.4683 - accuracy: 0.7946 - val_loss: 0.4755 - val_accuracy: 0.7868\n",
            "Epoch 12/100\n",
            "313/313 [==============================] - 11s 35ms/step - loss: 0.4586 - accuracy: 0.7986 - val_loss: 0.4665 - val_accuracy: 0.7868\n",
            "Epoch 13/100\n",
            "313/313 [==============================] - 11s 35ms/step - loss: 0.4509 - accuracy: 0.7998 - val_loss: 0.4627 - val_accuracy: 0.7890\n",
            "Epoch 14/100\n",
            "313/313 [==============================] - 11s 35ms/step - loss: 0.4455 - accuracy: 0.8027 - val_loss: 0.4611 - val_accuracy: 0.7890\n",
            "Epoch 15/100\n",
            "313/313 [==============================] - 11s 35ms/step - loss: 0.4405 - accuracy: 0.8055 - val_loss: 0.4550 - val_accuracy: 0.7890\n",
            "Epoch 16/100\n",
            "313/313 [==============================] - 11s 35ms/step - loss: 0.4367 - accuracy: 0.8055 - val_loss: 0.4569 - val_accuracy: 0.7906\n",
            "Epoch 17/100\n",
            "313/313 [==============================] - 11s 35ms/step - loss: 0.4336 - accuracy: 0.8073 - val_loss: 0.4499 - val_accuracy: 0.7934\n",
            "Epoch 18/100\n",
            "313/313 [==============================] - 11s 35ms/step - loss: 0.4304 - accuracy: 0.8095 - val_loss: 0.4527 - val_accuracy: 0.7900\n",
            "Epoch 19/100\n",
            "313/313 [==============================] - 11s 35ms/step - loss: 0.4280 - accuracy: 0.8080 - val_loss: 0.4468 - val_accuracy: 0.7958\n",
            "Epoch 20/100\n",
            "313/313 [==============================] - 11s 35ms/step - loss: 0.4254 - accuracy: 0.8105 - val_loss: 0.4461 - val_accuracy: 0.7952\n",
            "Epoch 21/100\n",
            "313/313 [==============================] - 11s 35ms/step - loss: 0.4237 - accuracy: 0.8110 - val_loss: 0.4449 - val_accuracy: 0.7942\n",
            "Epoch 22/100\n",
            "313/313 [==============================] - 11s 35ms/step - loss: 0.4212 - accuracy: 0.8112 - val_loss: 0.4446 - val_accuracy: 0.7944\n",
            "Epoch 23/100\n",
            "313/313 [==============================] - 11s 35ms/step - loss: 0.4195 - accuracy: 0.8117 - val_loss: 0.4423 - val_accuracy: 0.7976\n",
            "Epoch 24/100\n",
            "313/313 [==============================] - 11s 35ms/step - loss: 0.4177 - accuracy: 0.8143 - val_loss: 0.4436 - val_accuracy: 0.7986\n",
            "Epoch 25/100\n",
            "313/313 [==============================] - 11s 35ms/step - loss: 0.4163 - accuracy: 0.8149 - val_loss: 0.4418 - val_accuracy: 0.7990\n",
            "Epoch 26/100\n",
            "313/313 [==============================] - 11s 35ms/step - loss: 0.4150 - accuracy: 0.8152 - val_loss: 0.4387 - val_accuracy: 0.7972\n",
            "Epoch 27/100\n",
            "313/313 [==============================] - 11s 35ms/step - loss: 0.4140 - accuracy: 0.8151 - val_loss: 0.4402 - val_accuracy: 0.7982\n",
            "Epoch 28/100\n",
            "313/313 [==============================] - 11s 35ms/step - loss: 0.4128 - accuracy: 0.8137 - val_loss: 0.4380 - val_accuracy: 0.7998\n",
            "Epoch 29/100\n",
            "313/313 [==============================] - 11s 35ms/step - loss: 0.4117 - accuracy: 0.8152 - val_loss: 0.4372 - val_accuracy: 0.7960\n",
            "Epoch 30/100\n",
            "313/313 [==============================] - 11s 35ms/step - loss: 0.4104 - accuracy: 0.8170 - val_loss: 0.4370 - val_accuracy: 0.7960\n",
            "Epoch 31/100\n",
            "313/313 [==============================] - 11s 35ms/step - loss: 0.4095 - accuracy: 0.8170 - val_loss: 0.4355 - val_accuracy: 0.7974\n",
            "Epoch 32/100\n",
            "313/313 [==============================] - 11s 35ms/step - loss: 0.4088 - accuracy: 0.8160 - val_loss: 0.4354 - val_accuracy: 0.8012\n",
            "Epoch 33/100\n",
            "313/313 [==============================] - 11s 35ms/step - loss: 0.4075 - accuracy: 0.8169 - val_loss: 0.4350 - val_accuracy: 0.7988\n",
            "Epoch 34/100\n",
            "313/313 [==============================] - 11s 35ms/step - loss: 0.4070 - accuracy: 0.8168 - val_loss: 0.4367 - val_accuracy: 0.8032\n",
            "Epoch 35/100\n",
            "313/313 [==============================] - 11s 35ms/step - loss: 0.4061 - accuracy: 0.8177 - val_loss: 0.4382 - val_accuracy: 0.7932\n",
            "Epoch 36/100\n",
            "313/313 [==============================] - 11s 35ms/step - loss: 0.4051 - accuracy: 0.8178 - val_loss: 0.4355 - val_accuracy: 0.7984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2MXl2C3ZKaYp",
        "outputId": "0229f8a4-8f85-4c67-b430-9787847446c7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['train', 'val'])\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af_sR6S8K60T"
      },
      "source": [
        "<br><br>\n",
        "\n",
        "<h3> 순환층에 드롭아웃 적용하기 </h3>\n",
        "\n",
        "- 순환층의 자체적인 드롭아웃 기능 사용 (과대적합 예방 - train data에 의존성 막기 위함)\n",
        "\n",
        "1. dropout 매개변수 - 셀의 입력에 드롭아웃 적용\n",
        "2. recurrent_dropout 매개변수 - 순환되는 은닉 상태에 드롭아웃 적용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "l0MqXK9NKbZq",
        "outputId": "46164042-5074-42cc-f0c5-5ba3a039a3f0"
      },
      "source": [
        "model2 = keras.Sequential()\n",
        "\n",
        "model2.add(keras.layers.Embedding(500, 16, input_length=100))\n",
        "model2.add(keras.layers.LSTM(8, dropout=0.3)) # dropout  0.3 (30%입력 드롭아웃 적용)\n",
        "model2.add(keras.layers.Dense(1, activation='sigmoid’))\n",
        "\n",
        "rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)\n",
        "model2.compile(optimizer=rmsprop, loss='binary_crossentropy', \n",
        "               metrics=['accuracy'])\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint('best-dropout-model.h5', \n",
        "                                                save_best_only=True)\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3,\n",
        "                                                  restore_best_weights=True)\n",
        "\n",
        "history = model2.fit(train_seq, train_target, epochs=100, batch_size=64,\n",
        "                     validation_data=(val_seq, val_target),\n",
        "                     callbacks=[checkpoint_cb, early_stopping_cb])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-9d6c4ee87fd6>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    model2.add(keras.layers.Dense(1, activation='sigmoid’))\u001b[0m\n\u001b[0m                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_Dxj2DeKcmK"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['train', 'val'])\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euoPXpi8METo"
      },
      "source": [
        "<br>\n",
        "\n",
        "<h3> 2개의 층 연결하기 </h3>\n",
        "\n",
        "- 순환층 연결 할 때 은닉 상태를 마지막 타임 스텝에 대해 다음층으로 전달하기 위해, return_sequences 매개변수 True로 지정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV6gOGWUKdYK"
      },
      "source": [
        "model3 = keras.Sequential()\n",
        "\n",
        "model3.add(keras.layers.Embedding(500, 16, input_length=100))\n",
        "model3.add(keras.layers.LSTM(8, dropout=0.3, return_sequences=True)) # 앞쪽의 순환층이 모든 타임스텝에 대한 은닉상태 출력\n",
        "model3.add(keras.layers.LSTM(8, dropout=0.3))\n",
        "model3.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model3.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpgpTheKMWqT"
      },
      "source": [
        "<br><br>\n",
        "\n",
        "<h2> GRU (Gated Recurrent Unit) </h2>\n",
        "\n",
        "- LSTM의 간소화한 버전 (가중치, 파라미터 값이 LSTM보다 적어 계산량 적음)\n",
        "- 셀 상태를 계산하지 않고 은닉 상태 하나만 포함\n",
        "- 셀 3개: 2개의 시그모이드 활성화 함수 + 1개의 tanh 활성화 함수\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHvjhfMEMxAC",
        "outputId": "8c6f6368-718e-4bd8-b26c-b416dbc43d77"
      },
      "source": [
        "model4 = keras.Sequential()\n",
        "\n",
        "model4.add(keras.layers.Embedding(500, 16, input_length=100))\n",
        "model4.add(keras.layers.GRU(8))\n",
        "model4.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model4.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 100, 16)           8000      \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 8)                 624       \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 8,633\n",
            "Trainable params: 8,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWha3dy1MyOS",
        "outputId": "f279a869-f192-4ceb-be7f-c00719423798"
      },
      "source": [
        "rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)\n",
        "model4.compile(optimizer=rmsprop, loss='binary_crossentropy', \n",
        "               metrics=['accuracy'])\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint('best-gru-model.h5', \n",
        "                                                save_best_only=True)\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3,\n",
        "                                                  restore_best_weights=True)\n",
        "\n",
        "history = model4.fit(train_seq, train_target, epochs=100, batch_size=64,\n",
        "                     validation_data=(val_seq, val_target),\n",
        "                     callbacks=[checkpoint_cb, early_stopping_cb])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "313/313 [==============================] - 14s 40ms/step - loss: 0.6924 - accuracy: 0.5236 - val_loss: 0.6914 - val_accuracy: 0.5532\n",
            "Epoch 2/100\n",
            "313/313 [==============================] - 12s 38ms/step - loss: 0.6904 - accuracy: 0.5632 - val_loss: 0.6893 - val_accuracy: 0.5672\n",
            "Epoch 3/100\n",
            "313/313 [==============================] - 12s 38ms/step - loss: 0.6874 - accuracy: 0.5840 - val_loss: 0.6858 - val_accuracy: 0.5898\n",
            "Epoch 4/100\n",
            "313/313 [==============================] - 12s 38ms/step - loss: 0.6826 - accuracy: 0.6000 - val_loss: 0.6807 - val_accuracy: 0.5984\n",
            "Epoch 5/100\n",
            "313/313 [==============================] - 12s 38ms/step - loss: 0.6754 - accuracy: 0.6152 - val_loss: 0.6729 - val_accuracy: 0.6154\n",
            "Epoch 6/100\n",
            "313/313 [==============================] - 12s 38ms/step - loss: 0.6647 - accuracy: 0.6296 - val_loss: 0.6614 - val_accuracy: 0.6256\n",
            "Epoch 7/100\n",
            "313/313 [==============================] - 12s 38ms/step - loss: 0.6492 - accuracy: 0.6431 - val_loss: 0.6450 - val_accuracy: 0.6362\n",
            "Epoch 8/100\n",
            "313/313 [==============================] - 12s 38ms/step - loss: 0.6266 - accuracy: 0.6639 - val_loss: 0.6196 - val_accuracy: 0.6646\n",
            "Epoch 9/100\n",
            "313/313 [==============================] - 12s 38ms/step - loss: 0.5918 - accuracy: 0.6882 - val_loss: 0.5794 - val_accuracy: 0.7042\n",
            "Epoch 10/100\n",
            "313/313 [==============================] - 12s 38ms/step - loss: 0.5383 - accuracy: 0.7315 - val_loss: 0.5306 - val_accuracy: 0.7374\n",
            "Epoch 11/100\n",
            "313/313 [==============================] - 12s 38ms/step - loss: 0.5069 - accuracy: 0.7563 - val_loss: 0.5127 - val_accuracy: 0.7534\n",
            "Epoch 12/100\n",
            "313/313 [==============================] - 12s 38ms/step - loss: 0.4923 - accuracy: 0.7642 - val_loss: 0.5033 - val_accuracy: 0.7568\n",
            "Epoch 13/100\n",
            "313/313 [==============================] - 12s 39ms/step - loss: 0.4817 - accuracy: 0.7727 - val_loss: 0.4952 - val_accuracy: 0.7668\n",
            "Epoch 14/100\n",
            "313/313 [==============================] - 12s 39ms/step - loss: 0.4726 - accuracy: 0.7797 - val_loss: 0.4853 - val_accuracy: 0.7730\n",
            "Epoch 15/100\n",
            "313/313 [==============================] - 12s 38ms/step - loss: 0.4656 - accuracy: 0.7828 - val_loss: 0.4800 - val_accuracy: 0.7782\n",
            "Epoch 16/100\n",
            "313/313 [==============================] - 12s 38ms/step - loss: 0.4596 - accuracy: 0.7877 - val_loss: 0.4750 - val_accuracy: 0.7786\n",
            "Epoch 17/100\n",
            "313/313 [==============================] - 12s 39ms/step - loss: 0.4540 - accuracy: 0.7923 - val_loss: 0.4718 - val_accuracy: 0.7800\n",
            "Epoch 18/100\n",
            "313/313 [==============================] - 12s 38ms/step - loss: 0.4493 - accuracy: 0.7948 - val_loss: 0.4671 - val_accuracy: 0.7826\n",
            "Epoch 19/100\n",
            "313/313 [==============================] - 12s 39ms/step - loss: 0.4451 - accuracy: 0.7985 - val_loss: 0.4644 - val_accuracy: 0.7796\n",
            "Epoch 20/100\n",
            "313/313 [==============================] - 12s 39ms/step - loss: 0.4416 - accuracy: 0.8011 - val_loss: 0.4633 - val_accuracy: 0.7796\n",
            "Epoch 21/100\n",
            "313/313 [==============================] - 12s 39ms/step - loss: 0.4390 - accuracy: 0.8016 - val_loss: 0.4634 - val_accuracy: 0.7806\n",
            "Epoch 22/100\n",
            "313/313 [==============================] - 12s 39ms/step - loss: 0.4360 - accuracy: 0.8049 - val_loss: 0.4583 - val_accuracy: 0.7884\n",
            "Epoch 23/100\n",
            "313/313 [==============================] - 12s 39ms/step - loss: 0.4337 - accuracy: 0.8051 - val_loss: 0.4583 - val_accuracy: 0.7850\n",
            "Epoch 24/100\n",
            "313/313 [==============================] - 12s 39ms/step - loss: 0.4312 - accuracy: 0.8073 - val_loss: 0.4550 - val_accuracy: 0.7854\n",
            "Epoch 25/100\n",
            "313/313 [==============================] - 12s 38ms/step - loss: 0.4293 - accuracy: 0.8076 - val_loss: 0.4534 - val_accuracy: 0.7896\n",
            "Epoch 26/100\n",
            "313/313 [==============================] - 12s 38ms/step - loss: 0.4275 - accuracy: 0.8084 - val_loss: 0.4520 - val_accuracy: 0.7878\n",
            "Epoch 27/100\n",
            "313/313 [==============================] - 12s 38ms/step - loss: 0.4258 - accuracy: 0.8104 - val_loss: 0.4508 - val_accuracy: 0.7908\n",
            "Epoch 28/100\n",
            "313/313 [==============================] - 12s 38ms/step - loss: 0.4247 - accuracy: 0.8094 - val_loss: 0.4503 - val_accuracy: 0.7906\n",
            "Epoch 29/100\n",
            "313/313 [==============================] - 12s 38ms/step - loss: 0.4233 - accuracy: 0.8126 - val_loss: 0.4508 - val_accuracy: 0.7904\n",
            "Epoch 30/100\n",
            "313/313 [==============================] - 12s 38ms/step - loss: 0.4224 - accuracy: 0.8128 - val_loss: 0.4483 - val_accuracy: 0.7904\n",
            "Epoch 31/100\n",
            "313/313 [==============================] - 12s 38ms/step - loss: 0.4214 - accuracy: 0.8119 - val_loss: 0.4500 - val_accuracy: 0.7924\n",
            "Epoch 32/100\n",
            "313/313 [==============================] - 12s 38ms/step - loss: 0.4206 - accuracy: 0.8134 - val_loss: 0.4465 - val_accuracy: 0.7918\n",
            "Epoch 33/100\n",
            "313/313 [==============================] - 12s 37ms/step - loss: 0.4195 - accuracy: 0.8146 - val_loss: 0.4487 - val_accuracy: 0.7942\n",
            "Epoch 34/100\n",
            "313/313 [==============================] - 12s 37ms/step - loss: 0.4185 - accuracy: 0.8147 - val_loss: 0.4460 - val_accuracy: 0.7944\n",
            "Epoch 35/100\n",
            "313/313 [==============================] - 12s 37ms/step - loss: 0.4176 - accuracy: 0.8148 - val_loss: 0.4451 - val_accuracy: 0.7924\n",
            "Epoch 36/100\n",
            "313/313 [==============================] - 12s 37ms/step - loss: 0.4172 - accuracy: 0.8159 - val_loss: 0.4460 - val_accuracy: 0.7954\n",
            "Epoch 37/100\n",
            "313/313 [==============================] - 12s 37ms/step - loss: 0.4164 - accuracy: 0.8144 - val_loss: 0.4439 - val_accuracy: 0.7918\n",
            "Epoch 38/100\n",
            "313/313 [==============================] - 12s 37ms/step - loss: 0.4159 - accuracy: 0.8148 - val_loss: 0.4437 - val_accuracy: 0.7956\n",
            "Epoch 39/100\n",
            "313/313 [==============================] - 12s 37ms/step - loss: 0.4155 - accuracy: 0.8147 - val_loss: 0.4442 - val_accuracy: 0.7904\n",
            "Epoch 40/100\n",
            "313/313 [==============================] - 12s 37ms/step - loss: 0.4150 - accuracy: 0.8152 - val_loss: 0.4448 - val_accuracy: 0.7952\n",
            "Epoch 41/100\n",
            "313/313 [==============================] - 12s 37ms/step - loss: 0.4146 - accuracy: 0.8170 - val_loss: 0.4420 - val_accuracy: 0.7950\n",
            "Epoch 42/100\n",
            "313/313 [==============================] - 12s 37ms/step - loss: 0.4140 - accuracy: 0.8152 - val_loss: 0.4426 - val_accuracy: 0.7914\n",
            "Epoch 43/100\n",
            "313/313 [==============================] - 12s 37ms/step - loss: 0.4134 - accuracy: 0.8164 - val_loss: 0.4459 - val_accuracy: 0.7952\n",
            "Epoch 44/100\n",
            "313/313 [==============================] - 12s 38ms/step - loss: 0.4129 - accuracy: 0.8163 - val_loss: 0.4418 - val_accuracy: 0.7940\n",
            "Epoch 45/100\n",
            "313/313 [==============================] - 12s 37ms/step - loss: 0.4129 - accuracy: 0.8170 - val_loss: 0.4411 - val_accuracy: 0.7950\n",
            "Epoch 46/100\n",
            "313/313 [==============================] - 12s 37ms/step - loss: 0.4125 - accuracy: 0.8170 - val_loss: 0.4419 - val_accuracy: 0.7932\n",
            "Epoch 47/100\n",
            "313/313 [==============================] - 12s 37ms/step - loss: 0.4122 - accuracy: 0.8171 - val_loss: 0.4399 - val_accuracy: 0.7946\n",
            "Epoch 48/100\n",
            "313/313 [==============================] - 12s 37ms/step - loss: 0.4114 - accuracy: 0.8188 - val_loss: 0.4388 - val_accuracy: 0.7964\n",
            "Epoch 49/100\n",
            "313/313 [==============================] - 12s 37ms/step - loss: 0.4115 - accuracy: 0.8166 - val_loss: 0.4403 - val_accuracy: 0.7980\n",
            "Epoch 50/100\n",
            "313/313 [==============================] - 12s 38ms/step - loss: 0.4110 - accuracy: 0.8152 - val_loss: 0.4390 - val_accuracy: 0.7980\n",
            "Epoch 51/100\n",
            "313/313 [==============================] - 12s 38ms/step - loss: 0.4107 - accuracy: 0.8167 - val_loss: 0.4393 - val_accuracy: 0.7942\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNFXw126NX8r"
      },
      "source": [
        "test_seq = pad_sequences(test_input, maxlen=100)\n",
        "rnn_model = keras.models.load_model('best-2rnn-model.h5')\n",
        "rnn_model.evaluate(test_seq, test_target)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}